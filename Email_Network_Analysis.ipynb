{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "044c64f5",
   "metadata": {},
   "source": [
    "# In this notebook we use NetworkX to analyze a company's email network. Each employee is represented by a node and edges indicate that at least one email has been sent between them. Nodes also have attributes \"Department\" and \"ManagementSalary\" (Indicating if employee receives management salary). Dataset for this notebook has been downloaded from coursera."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c16723c",
   "metadata": {},
   "source": [
    "# Importing necessary libraries/packages and reading graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2554e07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: networkx 1.11\n",
      "Uninstalling networkx-1.11:\n",
      "  Successfully uninstalled networkx-1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "scikit-image 0.18.1 requires networkx>=2.0, but you have networkx 1.11 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting networkx==1.11\n",
      "  Using cached networkx-1.11-py2.py3-none-any.whl (1.3 MB)\n",
      "Requirement already satisfied: decorator>=3.4.0 in c:\\users\\16178\\anaconda3\\lib\\site-packages (from networkx==1.11) (5.0.6)\n",
      "Installing collected packages: networkx\n",
      "Successfully installed networkx-1.11\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "!pip uninstall networkx -y\n",
    "!pip install networkx==1.11\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "G = nx.read_gpickle('email_prediction.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c66f4ca",
   "metadata": {},
   "source": [
    "# Part I - Training a classifier to predict probability that an employee receives management salary. First find nodes for which information about management salary is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa993670",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "for node in list(G.nodes(data=True)) :\n",
    "    if not math.isnan(node[1]['ManagementSalary']) :\n",
    "        train.append(node[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0232819",
   "metadata": {},
   "source": [
    "# Obtaining features for training a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12168cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List containing information about dept of employees\n",
    "train_dept_list = []\n",
    "# List of booleans which tell whether an employee receives managment salary or not \n",
    "train_management_list = []\n",
    "# List containing clusteting coefficients of nodes\n",
    "train_clustering_list = []\n",
    "# List containing degree centrality of nodes\n",
    "train_degree_list = []\n",
    "for x in train :\n",
    "    train_dept_list.append(list(G.nodes(data=True))[x][1]['Department'])\n",
    "    train_management_list.append(list(G.nodes(data=True))[x][1]['ManagementSalary'])\n",
    "    train_clustering_list.append(nx.clustering(G, x))\n",
    "    train_degree_list.append(nx.degree_centrality(G)[x])\n",
    "# Dept of employees, their clustering coefficients and degree centrality values are used as features\n",
    "X_train = pd.DataFrame([train_dept_list, train_clustering_list, train_degree_list]).T\n",
    "X_train.columns = ['dept', 'clustering', 'degree']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb29391",
   "metadata": {},
   "source": [
    "# Obtaining one hot vectors for the column 'dept'. Also, the list of true labels is being obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "638ca9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "# Obtaining one hot vectors for dept of employees\n",
    "encoder_df = pd.DataFrame(encoder.fit_transform(X_train[['dept']]).toarray())\n",
    "df_data = X_train.join(encoder_df)\n",
    "df_data.drop('dept', axis=1, inplace=True)\n",
    "y_data = pd.DataFrame([train_management_list]).T\n",
    "y_data.columns = ['Management']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddaacd4f",
   "metadata": {},
   "source": [
    "# Training a classifier using grid search with area under ROC curve as metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffc9fd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC curve is 0.9226804123711341\n"
     ]
    }
   ],
   "source": [
    "# Training a random forest classifier along with hyper-parameter optimization using grid search \n",
    "clf_prior = RandomForestClassifier(random_state = 0)\n",
    "parameters = {'n_estimators': [6, 8, 10], 'max_depth': [5, 7]}\n",
    "clf = GridSearchCV(clf_prior, parameters, scoring ='roc_auc')\n",
    "clf.fit(df_data[:650], y_data[:650])\n",
    "# Area under ROC curve is used as metric\n",
    "print('Area under ROC curve is', roc_auc_score(y_data[650:], clf.predict_proba(df_data[650:])[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8535e3",
   "metadata": {},
   "source": [
    "# Part II - Predicting future connections - Given the status of graph and attributes of nodes at a certain stage, we will predict the probability of formation of an edge between nodes that were not connected initially. First we read the provided dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbeff218",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_connections = pd.read_csv('Future_Connections.csv', index_col=0, converters={0: eval})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1ad89b",
   "metadata": {},
   "source": [
    "# Classifying nodes into communities based on employee's department and finding out pairs of nodes for which information about future connection is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c53c049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in G.nodes(data=True) :\n",
    "    G.node[x[0]]['community'] = x[1]['Department']\n",
    "future_connections['check_nan'] = future_connections['Future Connection'].apply(lambda x: math.isnan(x))\n",
    "data_df = future_connections[future_connections['check_nan']==False]\n",
    "data_df.drop(['check_nan'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23aa593",
   "metadata": {},
   "source": [
    "# Obtaining features for training classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e109a8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find no. of common neighbors for pairs of nodes \n",
    "data_df['common_neighbors'] = data_df.index.map(lambda city: len(list(nx.common_neighbors(G, city[0], city[1]))))\n",
    "# Find list of Jaccard coefficients of pairs of nodes\n",
    "jaccard_coefficient_list = []\n",
    "# Find list of resource allocation index of pairs of nodes\n",
    "resource_allocation_list = []\n",
    "# Find list of adamic adar index of pairs of nodes\n",
    "adamic_adar_list = []\n",
    "# Find list of preferential attachment scores of pairs of nodes\n",
    "preferential_attachment_list = []\n",
    "# Finds no. of common neighbors for pairs of nodes using community information\n",
    "cn_soundarajan_list = []\n",
    "for x in list(data_df.index) :\n",
    "    jaccard_coefficient_list.append(list(nx.jaccard_coefficient(G, [x]))[0][2])\n",
    "    resource_allocation_list.append(list(nx.resource_allocation_index(G, [x]))[0][2])\n",
    "    adamic_adar_list.append(list(nx.adamic_adar_index(G, [x]))[0][2])\n",
    "    preferential_attachment_list.append(list(nx.preferential_attachment(G, [x]))[0][2])\n",
    "    cn_soundarajan_list.append(list(nx.cn_soundarajan_hopcroft(G, [x]))[0][2])\n",
    "data_df['jaccard_coefficient'] = jaccard_coefficient_list\n",
    "data_df['resource_allocation'] = resource_allocation_list\n",
    "data_df['adamic_adar'] = adamic_adar_list\n",
    "data_df['preferential_attachment'] = preferential_attachment_list\n",
    "data_df['cn_soundarajan'] = cn_soundarajan_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f902c7e7",
   "metadata": {},
   "source": [
    "# Training a classifier using grid search with area under ROC curve as metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "115a7e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC curve is 0.9197720856341671\n"
     ]
    }
   ],
   "source": [
    "clf_prior = RandomForestClassifier()\n",
    "parameters = {'n_estimators': [6, 8, 10], 'max_depth': [3, 4, 5]}\n",
    "# Train a random forest classifier with hyper-parameter optimization using grid search\n",
    "clf = GridSearchCV(clf_prior, parameters, scoring ='roc_auc')\n",
    "train_X = data_df[['common_neighbors', 'jaccard_coefficient', 'resource_allocation', 'adamic_adar',\n",
    "                   'preferential_attachment', 'cn_soundarajan']][:329700]\n",
    "train_y = data_df['Future Connection'][:329700]\n",
    "test_X = data_df[['common_neighbors', 'jaccard_coefficient', 'resource_allocation', 'adamic_adar',\n",
    "                  'preferential_attachment', 'cn_soundarajan']][329700:]\n",
    "test_y = data_df['Future Connection'][329700:]\n",
    "clf.fit(train_X, train_y)\n",
    "# Area under ROC curve is used as metric\n",
    "print('Area under ROC curve is', roc_auc_score(test_y, clf.predict_proba(test_X)[:, 1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
